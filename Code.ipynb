{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\TA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import importlib\n",
    "####\n",
    "import hashlib\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "####\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "######\n",
    "nltk.download('punkt')\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list_recursive(nested_list):\n",
    "    flat_list = []\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, list):\n",
    "            flat_list.extend(flatten_list_recursive(item))\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "    return flat_list\n",
    "\n",
    "def tokenize_category(category):\n",
    "    # Tokenize the category using NLTK's word_tokenize\n",
    "    tokens = word_tokenize(category.lower())\n",
    "    return tokens\n",
    "\n",
    "def hash_tokens(tokens):\n",
    "    # Hash the tokens using SHA-1 # sha-256 is too long\n",
    "    hashed_tokens = [hashlib.sha1(token.encode()).hexdigest() for token in tokens]\n",
    "    return hashed_tokens\n",
    "\n",
    "\n",
    "def get_hash_tokenised(df, cat_col):\n",
    "    #\n",
    "    uidx = df[cat_col].drop_duplicates().index\n",
    "    # Apply tokenization and hashing to the 'category_column'\n",
    "    df['tokens'] = df[cat_col].apply(tokenize_category)\n",
    "    df['hashed_tokens'] = df['tokens'].apply(hash_tokens)\n",
    "\n",
    "    # One-hot encode the hashed tokens\n",
    "    hashed_tokens_df = pd.get_dummies(df['hashed_tokens'].apply(pd.Series).stack()).groupby(level=0).sum()\n",
    "\n",
    "    # Combine the one-hot encoded DataFrame with the original DataFrame\n",
    "    df = pd.concat([df, hashed_tokens_df], axis=1)\n",
    "\n",
    "    # Drop the unnecessary columns\n",
    "    decrypt_labels = list(zip(flatten_list_recursive(df.tokens[uidx]),\n",
    "                              flatten_list_recursive(df.hashed_tokens[uidx])))\n",
    "  \n",
    "    return df.drop(columns=[cat_col, 'tokens', 'hashed_tokens']), decrypt_labels\\\n",
    "    \n",
    "\n",
    "def load_sklearn_function(module_name, function_name):\n",
    "    \"\"\"\n",
    "    Load a specific function from a given scikit-learn module.\n",
    "\n",
    "    Parameters:\n",
    "        module_name (str): The name of the scikit-learn module to import (e.g., 'sklearn.linear_model').\n",
    "        function_name (str): The name of the function to load from the specified module.\n",
    "\n",
    "    Returns:\n",
    "        function: The desired function object if found, or None if not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        module = importlib.import_module(module_name)\n",
    "        function = getattr(module, function_name, None)\n",
    "        return function\n",
    "    except ImportError:\n",
    "        print(f\"Error: The module '{module_name}' could not be imported.\")\n",
    "        return None\n",
    "    except AttributeError:\n",
    "        print(f\"Error: The function '{function_name}' was not found in module '{module_name}'.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reducer_trees(df, num_trees, depth, num_final_columns):\n",
    "    # Separate features and target variable\n",
    "    X = df.drop(columns='target')\n",
    "    y = df['target']\n",
    "\n",
    "    # Create a Random Forest Regressor model\n",
    "    model = RandomForestRegressor(n_estimators = num_trees, max_depth = depth)\n",
    "\n",
    "    # Fit the model to calculate feature importances\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Get feature importances\n",
    "    feature_importances = model.feature_importances_\n",
    "\n",
    "    # Sort the features based on importance scores\n",
    "    sorted_features = sorted(zip(X.columns, feature_importances), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Select the top N features based on the desired number of final columns\n",
    "    selected_features = [feature[0] for feature in sorted_features[:num_final_columns]]\n",
    "\n",
    "    # Create the reduced dataframe with the top N features and the target column\n",
    "    reduced_df = df[selected_features + ['target']]\n",
    "\n",
    "    return reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reducer_pca(df, target_column_name, num_final_columns):\n",
    "    # Separate features and target variable\n",
    "    X = df.drop(columns=target_column_name)\n",
    "    y = df[target_column_name]\n",
    "\n",
    "    # Create PCA object with the desired number of final columns\n",
    "    pca = PCA(n_components=num_final_columns)\n",
    "\n",
    "    # Fit and transform the data to the reduced number of columns\n",
    "    reduced_features = pca.fit_transform(X)\n",
    "\n",
    "    # Create a new DataFrame with the reduced features and the target column\n",
    "    reduced_df = pd.DataFrame(data=reduced_features, columns=[f\"PC{i}\" for i in range(1, num_final_columns + 1)])\n",
    "    reduced_df[target_column_name] = y\n",
    "\n",
    "    return reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reduer_corr(df, target_column_name, num_final_columns):\n",
    "    # Calculate the correlation between each feature and the target variable\n",
    "    correlations = df.corr()[target_column_name].abs().sort_values(ascending=False)\n",
    "\n",
    "    # Exclude the target variable from the correlation results\n",
    "    correlations = correlations.drop(target_column_name)\n",
    "\n",
    "    # Select the top N features based on the desired number of final columns\n",
    "    selected_features = list(correlations.index[:num_final_columns])\n",
    "\n",
    "    # Create the reduced dataframe with the top N features and the target column\n",
    "    reduced_df = df[selected_features + [target_column_name]]\n",
    "\n",
    "    return reduced_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_max_pairs(input_list):\n",
    "    min_max_pairs = []\n",
    "    remaining_items = set(input_list)  # Convert input_list to a set for faster lookups\n",
    "    for item in input_list:\n",
    "        if 'max' in item:\n",
    "            min_item = item.replace('max', 'min')\n",
    "            if min_item in remaining_items:\n",
    "                min_max_pairs.append((min_item, item))\n",
    "                remaining_items.remove(min_item)  # Remove the found items from the set\n",
    "                remaining_items.remove(item)\n",
    "    return min_max_pairs, list(remaining_items)  # Convert set back to list for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_model_name</th>\n",
       "      <th>task</th>\n",
       "      <th>module</th>\n",
       "      <th>function</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>regression</td>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>LinearRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGD</td>\n",
       "      <td>regression</td>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>SGDRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LassoRegression</td>\n",
       "      <td>regression</td>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>Lasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xg_boost</td>\n",
       "      <td>regression</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>regression</td>\n",
       "      <td>sklearn.tree</td>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>extra_random_trees</td>\n",
       "      <td>regression</td>\n",
       "      <td>sklearn.tree</td>\n",
       "      <td>ExtraTreeRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GBTRegressor</td>\n",
       "      <td>regression</td>\n",
       "      <td>sklearn.ensemble</td>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>regression</td>\n",
       "      <td>sklearn.ensemble</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM</td>\n",
       "      <td>regression</td>\n",
       "      <td>sklearn.svm</td>\n",
       "      <td>SVR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>neural_network</td>\n",
       "      <td>regression</td>\n",
       "      <td>sklearn.neural_network</td>\n",
       "      <td>MLPRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RidgeRegression</td>\n",
       "      <td>regression</td>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>Ridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ElasticNetRegression</td>\n",
       "      <td>regression</td>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>ElasticNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNN</td>\n",
       "      <td>regression</td>\n",
       "      <td>neighbors</td>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>classification</td>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>neural_network</td>\n",
       "      <td>classification</td>\n",
       "      <td>sklearn.neural_network</td>\n",
       "      <td>MLPClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SGD</td>\n",
       "      <td>classification</td>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>classification</td>\n",
       "      <td>sklearn.ensemble</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVM</td>\n",
       "      <td>classification</td>\n",
       "      <td>sklearn.svm</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>xg_boost</td>\n",
       "      <td>classification</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>classification</td>\n",
       "      <td>sklearn.tree</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>extra_random_trees</td>\n",
       "      <td>classification</td>\n",
       "      <td>sklearn.tree</td>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GBTClassifier</td>\n",
       "      <td>classification</td>\n",
       "      <td>sklearn.ensemble</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>KNN</td>\n",
       "      <td>classification</td>\n",
       "      <td>neighbors</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_model_name            task                  module  \\\n",
       "0         LinearRegression      regression    sklearn.linear_model   \n",
       "1                      SGD      regression    sklearn.linear_model   \n",
       "2          LassoRegression      regression    sklearn.linear_model   \n",
       "3                 xg_boost      regression                      NA   \n",
       "4    DecisionTreeRegressor      regression            sklearn.tree   \n",
       "5       extra_random_trees      regression            sklearn.tree   \n",
       "6             GBTRegressor      regression        sklearn.ensemble   \n",
       "7    RandomForestRegressor      regression        sklearn.ensemble   \n",
       "8                      SVM      regression             sklearn.svm   \n",
       "9           neural_network      regression  sklearn.neural_network   \n",
       "10         RidgeRegression      regression    sklearn.linear_model   \n",
       "11    ElasticNetRegression      regression    sklearn.linear_model   \n",
       "12                     KNN      regression               neighbors   \n",
       "13     Logistic Regression  classification    sklearn.linear_model   \n",
       "14          neural_network  classification  sklearn.neural_network   \n",
       "15                     SGD  classification    sklearn.linear_model   \n",
       "16  RandomForestClassifier  classification        sklearn.ensemble   \n",
       "17                     SVM  classification             sklearn.svm   \n",
       "18                xg_boost  classification                      NA   \n",
       "19  DecisionTreeClassifier  classification            sklearn.tree   \n",
       "20      extra_random_trees  classification            sklearn.tree   \n",
       "21           GBTClassifier  classification        sklearn.ensemble   \n",
       "22                     KNN  classification               neighbors   \n",
       "\n",
       "                      function  \n",
       "0             LinearRegression  \n",
       "1                 SGDRegressor  \n",
       "2                        Lasso  \n",
       "3                           NA  \n",
       "4        DecisionTreeRegressor  \n",
       "5           ExtraTreeRegressor  \n",
       "6    GradientBoostingRegressor  \n",
       "7        RandomForestRegressor  \n",
       "8                          SVR  \n",
       "9                 MLPRegressor  \n",
       "10                       Ridge  \n",
       "11                  ElasticNet  \n",
       "12         KNeighborsRegressor  \n",
       "13          LogisticRegression  \n",
       "14               MLPClassifier  \n",
       "15               SGDClassifier  \n",
       "16      RandomForestClassifier  \n",
       "17                         SVC  \n",
       "18                          NA  \n",
       "19      DecisionTreeClassifier  \n",
       "20         ExtraTreeClassifier  \n",
       "21  GradientBoostingClassifier  \n",
       "22        KNeighborsClassifier  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    (\"LinearRegression\", \"regression\", \"sklearn.linear_model\", \"LinearRegression\"),\n",
    "    (\"SGD\", \"regression\", \"sklearn.linear_model\", \"SGDRegressor\"),\n",
    "    (\"LassoRegression\", \"regression\", \"sklearn.linear_model\", \"Lasso\"),\n",
    "    (\"xg_boost\", \"regression\", \"NA\", \"NA\"),\n",
    "    (\"DecisionTreeRegressor\", \"regression\", \"sklearn.tree\", \"DecisionTreeRegressor\"),\n",
    "    (\"extra_random_trees\", \"regression\", \"sklearn.tree\", \"ExtraTreeRegressor\"),\n",
    "    (\"GBTRegressor\", \"regression\", \"sklearn.ensemble\", \"GradientBoostingRegressor\"),\n",
    "    (\"RandomForestRegressor\", \"regression\", \"sklearn.ensemble\", \"RandomForestRegressor\"),\n",
    "    (\"SVM\", \"regression\", \"sklearn.svm\", \"SVR\"),\n",
    "    (\"neural_network\", \"regression\", \"sklearn.neural_network\", \"MLPRegressor\"),\n",
    "    (\"RidgeRegression\", \"regression\", \"sklearn.linear_model\", \"Ridge\"),\n",
    "    (\"ElasticNetRegression\", \"regression\", \"sklearn.linear_model\", \"ElasticNet\"),\n",
    "    (\"KNN\", \"regression\", \"neighbors\", \"KNeighborsRegressor\"),\n",
    "    (\"Logistic Regression\", \"classification\", \"sklearn.linear_model\", \"LogisticRegression\"),\n",
    "    (\"neural_network\", \"classification\", \"sklearn.neural_network\", \"MLPClassifier\"),\n",
    "    (\"SGD\", \"classification\", \"sklearn.linear_model\", \"SGDClassifier\"),\n",
    "    (\"RandomForestClassifier\", \"classification\", \"sklearn.ensemble\", \"RandomForestClassifier\"),\n",
    "    (\"SVM\", \"classification\", \"sklearn.svm\", \"SVC\"),\n",
    "    (\"xg_boost\", \"classification\", \"NA\", \"NA\"),\n",
    "    (\"DecisionTreeClassifier\", \"classification\", \"sklearn.tree\", \"DecisionTreeClassifier\"),\n",
    "    (\"extra_random_trees\", \"classification\", \"sklearn.tree\", \"ExtraTreeClassifier\"),\n",
    "    (\"GBTClassifier\", \"classification\", \"sklearn.ensemble\", \"GradientBoostingClassifier\"),\n",
    "    (\"KNN\", \"classification\", \"neighbors\", \"KNeighborsClassifier\")\n",
    "]\n",
    "\n",
    "\n",
    "model_look_up = pd.DataFrame(data, columns=[\"user_model_name\", \"task\", \"module\", \"function\"])\n",
    "\n",
    "model_look_up\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_fpath = r'InputData\\algoparams_from_ui.json'\n",
    "with open(json_fpath) as obj:\n",
    "  json_content = obj.read()\n",
    "parsed_json_data = json.loads(json_content)\n",
    "# print(json_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore json file content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['session_name', 'session_description', 'design_state_data']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'session_info': {'project_id': '1',\n",
       "  'experiment_id': 'kkkk-11',\n",
       "  'dataset': 'iris_modified.csv',\n",
       "  'session_name': 'test',\n",
       "  'session_description': 'test'},\n",
       " 'target': {'prediction_type': 'Regression',\n",
       "  'target': 'petal_width',\n",
       "  'type': 'regression',\n",
       "  'partitioning': True},\n",
       " 'train': {'policy': 'Split the dataset',\n",
       "  'time_variable': 'sepal_length',\n",
       "  'sampling_method': 'No sampling(whole data)',\n",
       "  'split': 'Randomly',\n",
       "  'k_fold': False,\n",
       "  'train_ratio': 0,\n",
       "  'random_seed': 0},\n",
       " 'metrics': {'optomize_model_hyperparameters_for': 'AUC',\n",
       "  'optimize_threshold_for': 'F1 Score',\n",
       "  'compute_lift_at': 0,\n",
       "  'cost_matrix_gain_for_true_prediction_true_result': 1,\n",
       "  'cost_matrix_gain_for_true_prediction_false_result': 0,\n",
       "  'cost_matrix_gain_for_false_prediction_true_result': 0,\n",
       "  'cost_matrix_gain_for_false_prediction_false_result': 0},\n",
       " 'feature_handling': {'sepal_length': {'feature_name': 'sepal_length',\n",
       "   'is_selected': True,\n",
       "   'feature_variable_type': 'numerical',\n",
       "   'feature_details': {'numerical_handling': 'Keep as regular numerical feature',\n",
       "    'rescaling': 'No rescaling',\n",
       "    'make_derived_feats': False,\n",
       "    'missing_values': 'Impute',\n",
       "    'impute_with': 'Average of values',\n",
       "    'impute_value': 0}},\n",
       "  'sepal_width': {'feature_name': 'sepal_width',\n",
       "   'is_selected': True,\n",
       "   'feature_variable_type': 'numerical',\n",
       "   'feature_details': {'numerical_handling': 'Keep as regular numerical feature',\n",
       "    'rescaling': 'No rescaling',\n",
       "    'make_derived_feats': False,\n",
       "    'missing_values': 'Impute',\n",
       "    'impute_with': 'custom',\n",
       "    'impute_value': -1}},\n",
       "  'petal_length': {'feature_name': 'petal_length',\n",
       "   'is_selected': True,\n",
       "   'feature_variable_type': 'numerical',\n",
       "   'feature_details': {'numerical_handling': 'Keep as regular numerical feature',\n",
       "    'rescaling': 'No rescaling',\n",
       "    'make_derived_feats': False,\n",
       "    'missing_values': 'Impute',\n",
       "    'impute_with': 'Average of values',\n",
       "    'impute_value': 0}},\n",
       "  'petal_width': {'feature_name': 'petal_width',\n",
       "   'is_selected': True,\n",
       "   'feature_variable_type': 'numerical',\n",
       "   'feature_details': {'numerical_handling': 'Keep as regular numerical feature',\n",
       "    'rescaling': 'No rescaling',\n",
       "    'make_derived_feats': False,\n",
       "    'missing_values': 'Impute',\n",
       "    'impute_with': 'custom',\n",
       "    'impute_value': -2}},\n",
       "  'species': {'feature_name': 'species',\n",
       "   'is_selected': True,\n",
       "   'feature_variable_type': 'text',\n",
       "   'feature_details': {'text_handling': 'Tokenize and hash',\n",
       "    'hash_columns': 0}}},\n",
       " 'feature_generation': {'linear_interactions': [['petal_length',\n",
       "    'sepal_width']],\n",
       "  'linear_scalar_type': 'robust',\n",
       "  'polynomial_interactions': ['petal_length/sepal_width',\n",
       "   'petal_width/species'],\n",
       "  'explicit_pairwise_interactions': ['sepal_width/sepal_length',\n",
       "   'petal_width/sepal_length']},\n",
       " 'feature_reduction': {'feature_reduction_method': 'Tree-based',\n",
       "  'num_of_features_to_keep': '4',\n",
       "  'num_of_trees': '5',\n",
       "  'depth_of_trees': '6'},\n",
       " 'hyperparameters': {'stratergy': 'Grid Search',\n",
       "  'shuffle_grid': True,\n",
       "  'random_state': 1,\n",
       "  'max_iterations': 2,\n",
       "  'max_search_time': 3,\n",
       "  'parallelism': 5,\n",
       "  'cross_validation_stratergy': 'Time-based K-fold(with overlap)',\n",
       "  'num_of_folds': 6,\n",
       "  'split_ratio': 0,\n",
       "  'stratified': True},\n",
       " 'weighting_stratergy': {'weighting_stratergy_method': 'Sample weights',\n",
       "  'weighting_stratergy_weight_variable': 'petal_length'},\n",
       " 'probability_calibration': {'probability_calibration_method': 'Sigmoid - Platt Scaling'},\n",
       " 'algorithms': {'RandomForestClassifier': {'model_name': 'Random Forest Classifier',\n",
       "   'is_selected': False,\n",
       "   'min_trees': 10,\n",
       "   'max_trees': 30,\n",
       "   'feature_sampling_statergy': 'Default',\n",
       "   'min_depth': 20,\n",
       "   'max_depth': 30,\n",
       "   'min_samples_per_leaf_min_value': 5,\n",
       "   'min_samples_per_leaf_max_value': 50,\n",
       "   'parallelism': 0},\n",
       "  'RandomForestRegressor': {'model_name': 'Random Forest Regressor',\n",
       "   'is_selected': True,\n",
       "   'min_trees': 10,\n",
       "   'max_trees': 20,\n",
       "   'feature_sampling_statergy': 'Default',\n",
       "   'min_depth': 20,\n",
       "   'max_depth': 25,\n",
       "   'min_samples_per_leaf_min_value': 5,\n",
       "   'min_samples_per_leaf_max_value': 10,\n",
       "   'parallelism': 0},\n",
       "  'GBTClassifier': {'model_name': 'Gradient Boosted Trees',\n",
       "   'is_selected': False,\n",
       "   'num_of_BoostingStages': [67, 89],\n",
       "   'feature_sampling_statergy': 'Fixed number',\n",
       "   'learningRate': [],\n",
       "   'use_deviance': True,\n",
       "   'use_exponential': False,\n",
       "   'fixed_number': 22,\n",
       "   'min_subsample': 1,\n",
       "   'max_subsample': 2,\n",
       "   'min_stepsize': 0.1,\n",
       "   'max_stepsize': 0.5,\n",
       "   'min_iter': 20,\n",
       "   'max_iter': 40,\n",
       "   'min_depth': 5,\n",
       "   'max_depth': 7},\n",
       "  'GBTRegressor': {'model_name': 'Gradient Boosted Trees',\n",
       "   'is_selected': False,\n",
       "   'num_of_BoostingStages': [67, 89],\n",
       "   'feature_sampling_statergy': 'Fixed number',\n",
       "   'use_deviance': True,\n",
       "   'use_exponential': False,\n",
       "   'fixed_number': 22,\n",
       "   'min_subsample': 1,\n",
       "   'max_subsample': 2,\n",
       "   'min_stepsize': 0.1,\n",
       "   'max_stepsize': 0.5,\n",
       "   'min_iter': 20,\n",
       "   'max_iter': 40,\n",
       "   'min_depth': 5,\n",
       "   'max_depth': 7},\n",
       "  'LinearRegression': {'model_name': 'LinearRegression',\n",
       "   'is_selected': False,\n",
       "   'parallelism': 2,\n",
       "   'min_iter': 30,\n",
       "   'max_iter': 50,\n",
       "   'min_regparam': 0.5,\n",
       "   'max_regparam': 0.8,\n",
       "   'min_elasticnet': 0.5,\n",
       "   'max_elasticnet': 0.8},\n",
       "  'LogisticRegression': {'model_name': 'LogisticRegression',\n",
       "   'is_selected': False,\n",
       "   'parallelism': 2,\n",
       "   'min_iter': 30,\n",
       "   'max_iter': 50,\n",
       "   'min_regparam': 0.5,\n",
       "   'max_regparam': 0.8,\n",
       "   'min_elasticnet': 0.5,\n",
       "   'max_elasticnet': 0.8},\n",
       "  'RidgeRegression': {'model_name': 'RidgeRegression',\n",
       "   'is_selected': False,\n",
       "   'regularization_term': 'Specify values to test',\n",
       "   'min_iter': 30,\n",
       "   'max_iter': 50,\n",
       "   'min_regparam': 0.5,\n",
       "   'max_regparam': 0.8},\n",
       "  'LassoRegression': {'model_name': 'Lasso Regression',\n",
       "   'is_selected': False,\n",
       "   'regularization_term': 'Specify values to test',\n",
       "   'min_iter': 30,\n",
       "   'max_iter': 50,\n",
       "   'min_regparam': 0.5,\n",
       "   'max_regparam': 0.8},\n",
       "  'ElasticNetRegression': {'model_name': 'Lasso Regression',\n",
       "   'is_selected': False,\n",
       "   'regularization_term': 'Specify values to test',\n",
       "   'min_iter': 30,\n",
       "   'max_iter': 50,\n",
       "   'min_regparam': 0.5,\n",
       "   'max_regparam': 0.8,\n",
       "   'min_elasticnet': 0.5,\n",
       "   'max_elasticnet': 0.8},\n",
       "  'xg_boost': {'model_name': 'XG Boost',\n",
       "   'is_selected': False,\n",
       "   'use_gradient_boosted_tree': True,\n",
       "   'dart': True,\n",
       "   'tree_method': '',\n",
       "   'random_state': 0,\n",
       "   'max_num_of_trees': 0,\n",
       "   'early_stopping': True,\n",
       "   'early_stopping_rounds': 2,\n",
       "   'max_depth_of_tree': [56, 89],\n",
       "   'learningRate': [89, 76],\n",
       "   'l1_regularization': [77],\n",
       "   'l2_regularization': [78],\n",
       "   'gamma': [68],\n",
       "   'min_child_weight': [67],\n",
       "   'sub_sample': [67],\n",
       "   'col_sample_by_tree': [67],\n",
       "   'replace_missing_values': False,\n",
       "   'parallelism': 0},\n",
       "  'DecisionTreeRegressor': {'model_name': 'Decision Tree',\n",
       "   'is_selected': False,\n",
       "   'min_depth': 4,\n",
       "   'max_depth': 7,\n",
       "   'use_gini': False,\n",
       "   'use_entropy': True,\n",
       "   'min_samples_per_leaf': [12, 6],\n",
       "   'use_best': True,\n",
       "   'use_random': True},\n",
       "  'DecisionTreeClassifier': {'model_name': 'Decision Tree',\n",
       "   'is_selected': False,\n",
       "   'min_depth': 4,\n",
       "   'max_depth': 7,\n",
       "   'use_gini': False,\n",
       "   'use_entropy': True,\n",
       "   'min_samples_per_leaf': [12, 6],\n",
       "   'use_best': True,\n",
       "   'use_random': True},\n",
       "  'SVM': {'model_name': 'Support Vector Machine',\n",
       "   'is_selected': False,\n",
       "   'linear_kernel': True,\n",
       "   'rep_kernel': True,\n",
       "   'polynomial_kernel': True,\n",
       "   'sigmoid_kernel': True,\n",
       "   'c_value': [566, 79],\n",
       "   'auto': True,\n",
       "   'scale': True,\n",
       "   'custom_gamma_values': True,\n",
       "   'tolerance': 7,\n",
       "   'max_iterations': 7},\n",
       "  'SGD': {'model_name': 'Stochastic Gradient Descent',\n",
       "   'is_selected': False,\n",
       "   'use_logistics': True,\n",
       "   'use_modified_hubber_loss': False,\n",
       "   'max_iterations': False,\n",
       "   'tolerance': 56,\n",
       "   'use_l1_regularization': 'on',\n",
       "   'use_l2_regularization': 'on',\n",
       "   'use_elastic_net_regularization': True,\n",
       "   'alpha_value': [79, 56],\n",
       "   'parallelism': 1},\n",
       "  'KNN': {'model_name': 'KNN',\n",
       "   'is_selected': False,\n",
       "   'k_value': [78],\n",
       "   'distance_weighting': True,\n",
       "   'neighbour_finding_algorithm': 'Automatic',\n",
       "   'random_state': 0,\n",
       "   'p_value': 0},\n",
       "  'extra_random_trees': {'model_name': 'Extra Random Trees',\n",
       "   'is_selected': False,\n",
       "   'num_of_trees': [45, 489],\n",
       "   'feature_sampling_statergy': 'Square root and Logarithm',\n",
       "   'max_depth': [12, 45],\n",
       "   'min_samples_per_leaf': [78, 56],\n",
       "   'parallelism': 3},\n",
       "  'neural_network': {'model_name': 'Neural Network',\n",
       "   'is_selected': False,\n",
       "   'hidden_layer_sizes': [67, 89],\n",
       "   'activation': '',\n",
       "   'alpha_value': 0,\n",
       "   'max_iterations': 0,\n",
       "   'convergence_tolerance': 0,\n",
       "   'early_stopping': True,\n",
       "   'solver': 'ADAM',\n",
       "   'shuffle_data': True,\n",
       "   'initial_learning_rate': 0,\n",
       "   'automatic_batching': True,\n",
       "   'beta_1': 0,\n",
       "   'beta_2': 0,\n",
       "   'epsilon': 0,\n",
       "   'power_t': 0,\n",
       "   'momentum': 0,\n",
       "   'use_nesterov_momentum': False}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_keys = list(parsed_json_data.keys())\n",
    "json_keys\n",
    "parsed_json_data[json_keys[0]]\n",
    "parsed_json_data[json_keys[1]]\n",
    "# 'design_state_data' states the requirements\n",
    "parsed_json_data[json_keys[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rqs = parsed_json_data[json_keys[2]]\n",
    "main_keys = list(rqs.keys())\n",
    "# main_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ks in main_keys:\n",
    "#     print(f'{ks} contains {rqs[ks]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repo_algo_dict.keys()\n",
    "# for algo_name in list(repo_algo_dict.keys()):\n",
    "#     repo_algo_dict[algo_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in rqs['feature_handling'].keys():\n",
    "#     rqs['feature_handling'][item]\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction_type': 'Regression',\n",
       " 'target': 'petal_width',\n",
       " 'type': 'regression',\n",
       " 'partitioning': True}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Read the target and type of regression to be run\n",
    "rqs['target']\n",
    "fpath = r'InputData\\iris.csv'\n",
    "iris_data = pd.read_csv(fpath)\n",
    "iris_data.info()\n",
    "#Read the features (which are column names in the csv) and \n",
    "#figure out what missing imputation needs to be applied \n",
    "# and apply that to the columns loaded in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'petal_width'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traget_name = rqs['target']['target']\n",
    "traget_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay! No missing data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing sepal_length with mean\n",
      "Imputing sepal_width with custom value -1\n",
      "Imputing petal_length with mean\n",
      "Imputing petal_width with custom value -2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no feature reduction necessary\n",
      "species column is tokenized and hashed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['b2bd7ff5fd2270c1025fbb6413ec93a67607be31',\n",
       " '1739de3503d610e295d933ae2616e7be78b02d43',\n",
       " '43825f1f7dae87f9103b3ddf764783a01f57b982']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what columns are to be used for analysis\n",
    "col_booleans = [rqs['feature_handling'][col]['is_selected'] for col in iris_data.columns]\n",
    "iris_data_sub = iris_data.loc[:,col_booleans]\n",
    "# setting right the dtypes of all selected columns\n",
    "col_dtypes = [rqs['feature_handling'][col]['feature_variable_type'] for col in iris_data_sub.columns]\n",
    "for idx, x in enumerate(col_dtypes):\n",
    "    if x == 'numerical':\n",
    "        if is_numeric_dtype(iris_data_sub.iloc[:,idx]):\n",
    "            pass\n",
    "        else:\n",
    "            print('rectified numeric data with fase dtype')\n",
    "            iris_data_sub.iloc[:,idx] = pd.to_numeric(iris_data_sub.iloc[:,idx], errors = 'coerce')\n",
    "    elif x == 'text':\n",
    "        if is_string_dtype(iris_data_sub.iloc[:,idx]):\n",
    "            pass\n",
    "        else:\n",
    "            print('rectified text data with fase dtype')\n",
    "            iris_data_sub.iloc[:,idx] =  iris_data_sub.iloc[:,idx].astype(str)\n",
    "############replace blanks with np.nan\n",
    "iris_data_sub = iris_data_sub.replace(r'^\\s*$', np.nan, regex=True)\n",
    "###########check missing data#####\n",
    "msn_stats = iris_data_sub.isna().sum()\n",
    "msn_cols = list(msn_stats[msn_stats==0].index)\n",
    "if msn_stats.sum() == 0:\n",
    "    print('Yay! No missing data')\n",
    "else:\n",
    "    print('Oops! missing data found')\n",
    "    msn_cols = list(msn_stats[msn_stats==0].index)\n",
    "    print('Check {msn_cols}')\n",
    "# del msn_stats\n",
    "gc.collect();\n",
    "#######what to do with missing data######\n",
    "for col in msn_cols:\n",
    "    try:\n",
    "        if rqs['feature_handling'][col]['feature_details']['missing_values'] == 'Impute':\n",
    "            \n",
    "            imp_func = rqs['feature_handling'][col]['feature_details']['impute_with']\n",
    "            if imp_func == 'Average of values':\n",
    "                iris_data_sub[col] = iris_data_sub[col].fillna(iris_data_sub[col].mean())\n",
    "                print(f'Imputing {col} with mean')\n",
    "            elif imp_func == 'custom':\n",
    "                imp_val = rqs['feature_handling'][col]['feature_details']['impute_value']\n",
    "                iris_data_sub[col] = iris_data_sub[col].fillna(imp_val)\n",
    "                print(f'Imputing {col} with custom value {imp_val}')\n",
    "            else:\n",
    "                raise ValueError\n",
    "                print('Imputation technique not supported')\n",
    "    except KeyError:\n",
    "        pass\n",
    "iris_data_sub.head()\n",
    "reduct_boolean = True\n",
    "#######reduce data###########\n",
    "#No Reduction, Corr with Target, Tree-based, PCA.\n",
    "if 'No Reduction' in list(rqs['feature_reduction'].keys()):\n",
    "    print('no feature reduction necessary')\n",
    "    reduct_boolean = False\n",
    "    pass\n",
    "else:\n",
    "    if any(isinstance(i,dict) for i in rqs['feature_reduction'].values()): # if nested\n",
    "        print('feature reduction input should not be a nested dictionary')\n",
    "    else:\n",
    "        freduc_name = rqs['feature_reduction']['feature_reduction_method']\n",
    "        if (iris_data_sub.shape[1] -1)  == int(rqs['feature_reduction']['num_of_features_to_keep']):\n",
    "            print('no feature reduction necessary')\n",
    "            reduct_boolean = False\n",
    "        elif (iris_data_sub.shape[1] -1) > int(rqs['feature_reduction']['num_of_features_to_keep']):\n",
    "            if freduc_name.lower() == 'tree-based':\n",
    "                    num_trees = int(rqs['feature_reduction']['num_of_trees'])\n",
    "                    depth = int(rqs['feature_reduction']['depth_of_trees'])\n",
    "                    iris_data_subr = data_reducer_trees(iris_data_sub,  num_trees, depth,\n",
    "                                    num_final_columns = int(rqs['feature_reduction']['num_of_features_to_keep']))\n",
    "            elif freduc_name.lower() == 'correlation with target':\n",
    "                if 'text' in col_dtypes:\n",
    "                    print('cannot apply pearson corr to categorical datatype')\n",
    "                    raise ValueError\n",
    "                else:\n",
    "                    iris_data_subr = data_reduer_corr(iris_data_sub, \n",
    "                                                      target_column_name=traget_name, \n",
    "                                                      num_final_columns=int(rqs['feature_reduction']['num_of_features_to_keep']))\n",
    "            elif freduc_name.lower() == 'pca':\n",
    "                    iris_data_subr = data_reducer_pca(iris_data_sub, \n",
    "                                                      target_column_name=traget_name, \n",
    "                                                      num_final_columns=int(rqs['feature_reduction']['num_of_features_to_keep']))    \n",
    "            else:\n",
    "                raise ValueError\n",
    "            print('reduction method not supported')\n",
    "                 \n",
    "        else:\n",
    "            raise ValueError\n",
    "        \n",
    "if not reduct_boolean:\n",
    "    iris_data_subr = iris_data_sub.copy()\n",
    "    del iris_data_sub\n",
    "    # #######any feature  encoding###########\n",
    "    feature_handling_keys = [x+'_handling' for x in col_dtypes]\n",
    "    feature_handling_actions = [rqs['feature_handling'][col]['feature_details'][key] for col,key in zip(iris_data_subr.columns,feature_handling_keys)]\n",
    "    feature_handling_actions  = [None if 'Keep as' in x else x for x in feature_handling_actions]\n",
    "    for idx, item in enumerate(feature_handling_actions):\n",
    "        if item is None:\n",
    "            pass\n",
    "        elif item == 'Tokenize and hash':\n",
    "            cat_col = iris_data_subr.columns[idx]\n",
    "            print(f'{cat_col} column is tokenized and hashed')\n",
    "            iris_data_subr, label_mapping = get_hash_tokenised(iris_data_subr, cat_col)   \n",
    "        else:\n",
    "            raise ValueError\n",
    "    encoded_cols = [x[1] for x in label_mapping]\n",
    "    encoded_cols\n",
    "    ###########feature reduction###########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Regression'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'Random Forest Regressor',\n",
       " 'is_selected': True,\n",
       " 'min_trees': 10,\n",
       " 'max_trees': 20,\n",
       " 'feature_sampling_statergy': 'Default',\n",
       " 'min_depth': 20,\n",
       " 'max_depth': 25,\n",
       " 'min_samples_per_leaf_min_value': 5,\n",
       " 'min_samples_per_leaf_max_value': 10,\n",
       " 'parallelism': 0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#whether classification or regression\n",
    "rqs['target']['prediction_type']\n",
    "# get algorithm\n",
    "repo_algo_dict = rqs['algorithms']\n",
    "for algo_name in list(repo_algo_dict.keys()):\n",
    "    # repo_algo_dict[algo_name]\n",
    "    if repo_algo_dict[algo_name]['is_selected'] == False:\n",
    "        pass\n",
    "    else:\n",
    "        repo_algo_dict[algo_name]\n",
    "        algo2use = algo_name\n",
    "        params = repo_algo_dict[algo_name]\n",
    "        break\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.ensemble._forest.RandomForestRegressor"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_basket = []\n",
    "for algo_name in list(repo_algo_dict.keys()):\n",
    "    model_basket.append(repo_algo_dict[algo_name]['model_name'])\n",
    "if rqs['target']['prediction_type'].lower() == 'regression':\n",
    "    algo_universe = [\n",
    "                    'LinearRegression', #sklearn.linear_model,linear_model.SGDRegressor\n",
    "                    'SGD', #sklearn.linear_model\n",
    "                    'LassoRegression', #sklearn.linear_model\n",
    "                    'ElasticNetRegression', #sklearn.linear_model\n",
    "                    'xg_boost', # import xgboost\n",
    "                    'DecisionTreeRegressor', #sklearn.tree, DecisionTreeRegressor\n",
    "                    'extra_random_trees', #sklearn.tree, ExtraTreeRegressor\n",
    "                    'GBDTRegressor', #sklearn.ensemble.GradientBoostingRegressor\n",
    "                    'RandomForestRegressor', #ensemble.RandomForestRegressor\n",
    "                    'SVM', # sklearn.svm.SVR\n",
    "                    'neural_network', # sklearn.neural_network.MLPRegressor\n",
    "                    'RidgeRegression' #sklearn.linear_model, linear_model.Ridge\n",
    "                    'KNN' #neighbors.KNeighborsRegressor\n",
    "                    ]\n",
    "else:\n",
    "    algo_universe = ['LogisticRegression',#sklearn.linear_model.LogisticRegression¶\n",
    "                     'SGD', #sklearn.linear_model, linear_model.SGDClassifier\n",
    "                    'RandomForestClassifier', #ensemble.RandomForestClassifier\n",
    "                    'SVM',# sklearn.svm.SVC\n",
    "                    'xg_boost', # import xgboost\n",
    "                        'DecisionTreeClassifier', ##sklearn.tree, DecisionTreeClassifier\n",
    "                    'extra_random_trees', ##sklearn.tree, ExtraTreeClassifier\n",
    "                    'GBTClassifier', # #sklearn.ensemble.GradientBoostingClassifier\n",
    "                    'neural_network', # sklearn.neural_network.MLPClassifier\n",
    "                    'KNN' # neighbors.KNeighborsClassifier\n",
    "                    ]\n",
    "if algo2use not in algo_universe:\n",
    "    print('wrong model for the task')\n",
    "else:\n",
    "    loaded_sklearn_model = load_sklearn_function(module_name = model_look_up.loc[model_look_up.user_model_name == algo2use, 'module'].item(), \n",
    "                                                function_name = model_look_up.loc[model_look_up.user_model_name == algo2use, 'function'].item())\n",
    "    loaded_sklearn_model \n",
    "#do hyper parameter tuning i.e., use GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Random Forest Regressor'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'min_trees': 10,\n",
       " 'max_trees': 20,\n",
       " 'feature_sampling_statergy': 'Default',\n",
       " 'min_depth': 20,\n",
       " 'max_depth': 25,\n",
       " 'min_samples_per_leaf_min_value': 5,\n",
       " 'min_samples_per_leaf_max_value': 10,\n",
       " 'parallelism': 0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs: [('min_trees', 'max_trees'), ('min_depth', 'max_depth'), ('min_samples_per_leaf_min_value', 'min_samples_per_leaf_max_value')]\n",
      "Single Elements: ['parallelism', 'feature_sampling_statergy']\n"
     ]
    }
   ],
   "source": [
    "if rqs['target']['prediction_type'].lower() == 'regression':\n",
    "    scorer = make_scorer(mean_squared_error)\n",
    "else:\n",
    "    scorer = 'roc_auc'\n",
    "\n",
    "params = repo_algo_dict[algo2use]\n",
    "params.pop('model_name', None)\n",
    "params.pop('is_selected', None)\n",
    "params\n",
    "\n",
    "pairs, single_elements = find_min_max_pairs(list(params.keys()))\n",
    "print(\"Pairs:\", pairs)\n",
    "print(\"Single Elements:\", single_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       " 'max_depth': [20, 21, 22, 23, 24],\n",
       " 'min_samples_leaf': [5, 6, 7, 8, 9, 10]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_grid = {}\n",
    "for min_item,max_item in pairs:\n",
    "    if 'trees' in max_item:\n",
    "        hp_grid['n_estimators'] = list(range(params[min_item], params[max_item]+1))\n",
    "    elif 'sample' in max_item:\n",
    "        hp_grid['min_samples_leaf'] = list(range(params[min_item], params[max_item]+1))\n",
    "    elif 'depth' in max_item:\n",
    "        hp_grid['max_depth'] = list(range(params[min_item], params[max_item]))\n",
    "    else:\n",
    "        raise ValueError\n",
    "        print('hp name not supported')\n",
    "\n",
    "hp_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Grid Search'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'shuffle_grid': True,\n",
       " 'random_state': 1,\n",
       " 'max_iterations': 2,\n",
       " 'max_search_time': 3,\n",
       " 'parallelism': 5,\n",
       " 'cross_validation_stratergy': 'Time-based K-fold(with overlap)',\n",
       " 'num_of_folds': 6,\n",
       " 'split_ratio': 0,\n",
       " 'stratified': True}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'squared_error',\n",
       " 'max_depth': None,\n",
       " 'max_features': 1.0,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_params = rqs['hyperparameters']\n",
    "grid_search_params.pop('stratergy', None)\n",
    "grid_search_params\n",
    "\n",
    "init_model = loaded_sklearn_model(random_state= int(grid_search_params['random_state']))\n",
    "init_model.get_params()\n",
    "\n",
    "cv_model = GridSearchCV(init_model, \n",
    "             hp_grid, \n",
    "             scoring = scorer, \n",
    "             n_jobs= int(grid_search_params['parallelism']), \n",
    "             refit=True, \n",
    "             cv = int(grid_search_params['num_of_folds']), #integer, to specify the number of folds in a (Stratified)KFold,\n",
    "             verbose=0, \n",
    "            #  error_score=nan, \n",
    "             return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=6, estimator=RandomForestRegressor(random_state=1), n_jobs=5,\n",
       "             param_grid={&#x27;max_depth&#x27;: [20, 21, 22, 23, 24],\n",
       "                         &#x27;min_samples_leaf&#x27;: [5, 6, 7, 8, 9, 10],\n",
       "                         &#x27;n_estimators&#x27;: [10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "                                          19, 20]},\n",
       "             scoring=make_scorer(mean_squared_error))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=6, estimator=RandomForestRegressor(random_state=1), n_jobs=5,\n",
       "             param_grid={&#x27;max_depth&#x27;: [20, 21, 22, 23, 24],\n",
       "                         &#x27;min_samples_leaf&#x27;: [5, 6, 7, 8, 9, 10],\n",
       "                         &#x27;n_estimators&#x27;: [10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "                                          19, 20]},\n",
       "             scoring=make_scorer(mean_squared_error))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=6, estimator=RandomForestRegressor(random_state=1), n_jobs=5,\n",
       "             param_grid={'max_depth': [20, 21, 22, 23, 24],\n",
       "                         'min_samples_leaf': [5, 6, 7, 8, 9, 10],\n",
       "                         'n_estimators': [10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "                                          19, 20]},\n",
       "             scoring=make_scorer(mean_squared_error))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.fit(iris_data_subr.drop(columns = [traget_name]), \n",
    "             iris_data_subr[traget_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 20, 'min_samples_leaf': 5, 'n_es...</td>\n",
       "      <td>0.030078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>{'max_depth': 24, 'min_samples_leaf': 5, 'n_es...</td>\n",
       "      <td>0.030078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>{'max_depth': 21, 'min_samples_leaf': 5, 'n_es...</td>\n",
       "      <td>0.030078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>{'max_depth': 22, 'min_samples_leaf': 5, 'n_es...</td>\n",
       "      <td>0.030078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>{'max_depth': 23, 'min_samples_leaf': 5, 'n_es...</td>\n",
       "      <td>0.030078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>{'max_depth': 22, 'min_samples_leaf': 10, 'n_e...</td>\n",
       "      <td>0.042205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>{'max_depth': 24, 'min_samples_leaf': 10, 'n_e...</td>\n",
       "      <td>0.042205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>{'max_depth': 23, 'min_samples_leaf': 10, 'n_e...</td>\n",
       "      <td>0.042205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>{'max_depth': 20, 'min_samples_leaf': 10, 'n_e...</td>\n",
       "      <td>0.042205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>{'max_depth': 21, 'min_samples_leaf': 10, 'n_e...</td>\n",
       "      <td>0.042205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                params  mean_test_score\n",
       "0    {'max_depth': 20, 'min_samples_leaf': 5, 'n_es...         0.030078\n",
       "264  {'max_depth': 24, 'min_samples_leaf': 5, 'n_es...         0.030078\n",
       "66   {'max_depth': 21, 'min_samples_leaf': 5, 'n_es...         0.030078\n",
       "132  {'max_depth': 22, 'min_samples_leaf': 5, 'n_es...         0.030078\n",
       "198  {'max_depth': 23, 'min_samples_leaf': 5, 'n_es...         0.030078\n",
       "..                                                 ...              ...\n",
       "193  {'max_depth': 22, 'min_samples_leaf': 10, 'n_e...         0.042205\n",
       "325  {'max_depth': 24, 'min_samples_leaf': 10, 'n_e...         0.042205\n",
       "259  {'max_depth': 23, 'min_samples_leaf': 10, 'n_e...         0.042205\n",
       "61   {'max_depth': 20, 'min_samples_leaf': 10, 'n_e...         0.042205\n",
       "127  {'max_depth': 21, 'min_samples_leaf': 10, 'n_e...         0.042205\n",
       "\n",
       "[330 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorted(cv_model.cv_results_.keys())\n",
    "cv_table = pd.DataFrame(cv_model.cv_results_)[['params','mean_test_score']].sort_values('mean_test_score', ascending=True)\n",
    "cv_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
